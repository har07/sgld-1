{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sgld\n",
    "import os\n",
    "import labnotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_string = \"postgres://postgres:1@localhost/experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, steps, modelparams = labnotebook.initialize(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'sgld' has no attribute 'GGDO'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cd2786b7ff24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'sgld.GGDO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m              'parametric_step': True}\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msgld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sgld/trainer.py\u001b[0m in \u001b[0;36mrunall\u001b[0;34m(cuda_device, model_desc, db_string)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sgld'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         optimizer = eval(model_desc['optimizer'])(model.parameters(),\n\u001b[0m\u001b[1;32m     22\u001b[0m                          \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                          addnoise=model_desc['addnoise'])\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sgld/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sgld' has no attribute 'GGDO'"
     ]
    }
   ],
   "source": [
    "model_desc = {'lr': 0.1,\n",
    "              'lr_epoch': 10,\n",
    "             'epochs': 1,\n",
    "             'step_samples': 10,\n",
    "             'percentage_tosample': .1,\n",
    "             'seed': 1,\n",
    "             'addnoise': True,\n",
    "             'optimizer': 'sgld.GGDO',\n",
    "             'parametric_step': True}\n",
    "sgld.runall(0, model_desc, db_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 0.200\tAcc: 95.230\tVal Acc: 92.612\n",
      "Epoch: 1\tLoss: 0.135\tAcc: 97.368\tVal Acc: 96.356\n",
      "Epoch: 2\tLoss: 0.107\tAcc: 98.520\tVal Acc: 97.520\n",
      "Epoch: 3\tLoss: 0.096\tAcc: 98.849\tVal Acc: 98.049\n",
      "Epoch: 4\tLoss: 0.086\tAcc: 98.849\tVal Acc: 98.229\n",
      "Epoch: 5\tLoss: 0.073\tAcc: 98.849\tVal Acc: 98.474\n",
      "Epoch: 6\tLoss: 0.064\tAcc: 99.013\tVal Acc: 98.659\n",
      "Epoch: 7\tLoss: 0.055\tAcc: 99.178\tVal Acc: 98.753\n",
      "Epoch: 8\tLoss: 0.049\tAcc: 99.178\tVal Acc: 98.802\n",
      "Epoch: 9\tLoss: 0.074\tAcc: 98.520\tVal Acc: 98.310\n",
      "Total number of steps: 590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run 314 on GPU 0 at 2018-03-30 16:38:32.482224"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgld.runall(0, model_desc, db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/henripal/projects/sgld/sgld/sgld/eval.py\u001b[0m(50)\u001b[0;36miterate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     48 \u001b[0;31m                    \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     49 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 50 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m                    \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m                    \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f35d961f048>\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    cl         disable  interact  next    psource  rv         unt   \n",
      "a      clear      display  j         p       q        s          until \n",
      "alias  commands   down     jump      pdef    quit     source     up    \n",
      "args   condition  enable   l         pdoc    r        step       w     \n",
      "b      cont       exit     list      pfile   restart  tbreak     whatis\n",
      "break  continue   h        ll        pinfo   return   u          where \n",
      "bt     d          help     longlist  pinfo2  retval   unalias  \n",
      "c      debug      ignore   n         pp      run      undisplay\n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "(0, [\n",
      "( 0  , 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "        ⋮  \n",
      "\n",
      "( 1  , 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "        ⋮  \n",
      "\n",
      "( 2  , 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " ...      \n",
      "        ⋮  \n",
      "\n",
      "(4093, 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "        ⋮  \n",
      "\n",
      "(4094, 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "        ⋮  \n",
      "\n",
      "(4095, 0  ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 4096x1x28x28]\n",
      ", \n",
      " 7\n",
      " 2\n",
      " 1\n",
      "⋮ \n",
      " 9\n",
      " 5\n",
      " 9\n",
      "[torch.LongTensor of size 4096]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = Process(target=sgld.runall, args=(0, model_desc, db_string))\n",
    "p2 = Process(target=sgld.runall, args=(1, model_desc2, db_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/henripal/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/henripal/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/henripal/projects/sgld/sgld/sgld/trainer.py\", line 39, in runall\n",
      "    cuda_device\n",
      "  File \"/home/henripal/projects/sgld/sgld/sgld/trainer.py\", line 161, in train\n",
      "    val_accuracy))\n",
      "TypeError: unsupported format string passed to Variable.__format__\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/henripal/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/henripal/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/henripal/projects/sgld/sgld/sgld/trainer.py\", line 39, in runall\n",
      "    cuda_device\n",
      "  File \"/home/henripal/projects/sgld/sgld/sgld/trainer.py\", line 161, in train\n",
      "    val_accuracy))\n",
      "TypeError: unsupported format string passed to Variable.__format__\n"
     ]
    }
   ],
   "source": [
    "p1.start()\n",
    "p2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.terminate()\n",
    "p2.terminate()\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisxp = xpbase.session.query(experiments).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisxp=labnotebook.session.query(experiments).order_by(experiments.run_id.desc()).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xp in thisxp:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = labnotebook.session.query(steps.custom_fields).filter(steps.run_id==230).filter(\n",
    "    steps.timestep==1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in q:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][0] is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisxp.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = [x for l in ha[0].values() for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ha[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(firststep.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firststep.experiment is xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.randint(3, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainacc = xpbase.session.query(steps.trainacc).filter(steps.run_id == 22).all()\n",
    "valacc = xpbase.session.query(steps.valacc).filter(steps.run_id == 22).all()\n",
    "trainloss = xpbase.session.query(steps.trainloss).filter(steps.run_id == 22).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = Figure(data=[Scatter(x=[1, 2, 3], y=[1, 2, 3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data[0].x.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data[0].extend([Scatter(x=[4], y=[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(trainacc)\n",
    "plt.plot(valacc)\n",
    "plt.figure()\n",
    "plt.plot(np.log(trainloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withnoise_histo = torch.load(os.path.join(basedir, \n",
    "                                          'withnoise_best_3', 'histo'))\n",
    "nonoise_histo = torch.load(os.path.join(basedir, \n",
    "                                          'nonoise_best_3', 'histo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withnoise_histo_np = sgld.state_dict_histo_2_numpy(withnoise_histo)\n",
    "nonoise_histo_np = sgld.state_dict_histo_2_numpy(nonoise_histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=15)\n",
    "plt.plot(withnoise['loss'], label='Langevin GD')\n",
    "plt.plot(nonoise['loss'], label='SGD')\n",
    "plt.legend()\n",
    "plt.xlabel('training time')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisy_std = sgld.apply_rolling2D(withnoise_histo_np,\n",
    "                    lambda x: np.std(x, axis=1), 40)\n",
    "clean_std = sgld.apply_rolling2D(nonoise_histo_np,\n",
    "                    lambda x: np.std(x, axis=1), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi_noisy = np.max(noisy_std, axis=1)\n",
    "maxi_clean = np.max(clean_std, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.semilogy(maxi_noisy, label='Langevin GD')\n",
    "plt.semilogy(maxi_clean, label='SGD')\n",
    "plt.legend()\n",
    "plt.xlabel('training time')\n",
    "plt.ylabel('Max St.Dev. of Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_id = sgld.apply_rolling2D(withnoise_histo_np[:, :2000],\n",
    "                               lambda x: x, 100, stack=False)\n",
    "clean_id = sgld.apply_rolling2D(nonoise_histo_np[:, :2000],\n",
    "                               lambda x: x, 100, stack=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = sgld.plot_densities(noisy_id[14], n_indices=20, \n",
    "                            n_bins=30, \n",
    "                            alpha=.4,\n",
    "                           burnin=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgld.plot_densities(clean_id[14], n_indices=10,\n",
    "                    n_bins=100,\n",
    "                    alpha=.4, \n",
    "                    delta=delta,\n",
    "                   burnin=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usable_statedict = OrderedDict()\n",
    "for k, v in nonoise_histo[-1].items():\n",
    "    usable_statedict[k] = torch.Tensor(v).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sgld.MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(usable_statedict)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = sgld.make_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proba distribution on notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotMnist(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filelist = glob.glob(os.path.join(self.root_dir, '**', '*.png'))\n",
    "        new_filelist = []\n",
    "        for file in self.filelist:\n",
    "            try:\n",
    "                io.imread(file)\n",
    "                new_filelist.append(file)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        self.filelist = new_filelist\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.filelist[idx])\n",
    "        image = PIL.Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            return self.transform(image)\n",
    "        return image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notmnist = NotMnist(root_dir = '../data/notMNIST_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 256\n",
    "notmnist_loader = torch.utils.data.DataLoader(NotMnist('../data/notMNIST_small',\n",
    "                                                      transform=transforms.ToTensor()), batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "notmnist_probas = []\n",
    "for data in notmnist_loader:\n",
    "    data = Variable(data, volatile=True)\n",
    "    data = data.cuda()\n",
    "    output = model(data)\n",
    "    notmnist_probas.append(output.max(1)[0].cpu().data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notmnist_probas = np.hstack(notmnist_probas)\n",
    "notmnist_probas = np.exp(notmnist_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(notmnist_probas), np.std(notmnist_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(notmnist_probas, bins=20, density=True, alpha = .8) ;\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proba distribution on mnist (correct and incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "probas = []\n",
    "acc = []\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "    data = data.cuda()\n",
    "    target = target.cuda()\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    proba = output.data.max(1)[0]\n",
    "    probas.append(proba.cpu().numpy())\n",
    "    acc.append(prediction.eq(target.data))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = np.hstack(probas)\n",
    "acc = np.hstack(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_probas = np.exp(probas[acc == 1])\n",
    "incorrect_probas = np.exp(probas[acc == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_probas.shape, incorrect_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(correct_probas), np.std(correct_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(incorrect_probas), np.std(incorrect_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(correct_probas, bins=20, density=True, alpha = .8, label='correct');\n",
    "plt.hist(incorrect_probas, bins=20, density=True, alpha=.8, label='incorrect');\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Bayesian. Basic MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_statedict(idx, histo):\n",
    "    usable_statedict = OrderedDict()\n",
    "    for k, v in histo[idx].items():\n",
    "        usable_statedict[k] = torch.Tensor(v).cuda()\n",
    "    return usable_statedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas = []\n",
    "bayes_targets = []\n",
    "\n",
    "for i in np.arange(-1, -20, -1):\n",
    "    model = sgld.MnistModel()\n",
    "    state_dict = make_statedict(i, withnoise_histo)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_probas = np.zeros((10000, 10))\n",
    "    epoch_targets = np.zeros((10000,))\n",
    "\n",
    "    for idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        output = model(data)\n",
    "        proba = output.data\n",
    "        epoch_probas[idx * test_loader.batch_size:(idx + 1) * test_loader.batch_size, :] = proba.cpu().numpy()\n",
    "        epoch_targets[idx * test_loader.batch_size:(idx + 1) * test_loader.batch_size] = target.cpu().data.numpy()\n",
    "        \n",
    "    bayes_probas.append(epoch_probas)\n",
    "    bayes_targets.append(epoch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas = np.stack(bayes_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_targets = bayes_targets[0].astype(int)\n",
    "bayes_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_averaged_probas = np.mean(bayes_probas, axis=0)\n",
    "bayes_averaged_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_max_probas = np.exp(bayes_averaged_probas.max(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_predictions = np.argmax(bayes_averaged_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_correct_probas = bayes_max_probas[bayes_predictions == bayes_targets]\n",
    "bayes_incorrect_probas = bayes_max_probas[bayes_predictions != bayes_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_correct_probas.shape, bayes_incorrect_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_correct_probas), np.std(bayes_correct_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_incorrect_probas), np.std(bayes_incorrect_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(bayes_correct_probas, bins=20, density=True, alpha = .8, label='correct');\n",
    "plt.hist(bayes_incorrect_probas, bins=20, density=True, alpha=.8, label='incorrect');\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian. NotMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas_nm = []\n",
    "\n",
    "for i in np.arange(-1, -20, -1):\n",
    "    model = sgld.MnistModel()\n",
    "    state_dict = make_statedict(i, withnoise_histo)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_probas = np.zeros((18724, 10))\n",
    "\n",
    "    for idx, data in enumerate(notmnist_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        data = data.cuda()\n",
    "        output = model(data)\n",
    "        proba = output.data\n",
    "        epoch_probas[idx * notmnist_loader.batch_size:(idx + 1) * notmnist_loader.batch_size, :] = proba.cpu().numpy()\n",
    "        \n",
    "    bayes_probas_nm.append(epoch_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas_nm = np.stack(bayes_probas_nm)\n",
    "bayes_averaged_probas_nm = np.mean(bayes_probas_nm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_max_probas_nm = np.exp(bayes_averaged_probas_nm.max(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_max_probas_nm), np.std(bayes_max_probas_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(notmnist_probas, bins=20, density=True, alpha = .8, label='SGD') ;\n",
    "plt.hist(bayes_max_probas_nm, bins=20, density=True, alpha = .8, label='Langevin SGD') ;\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}